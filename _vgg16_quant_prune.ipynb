{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pyfiles import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "stype = 'os'\n",
    "\n",
    "sparsity = 0.80\n",
    "float_model_path = f\"result/__VGG16_{stype}_prune/model_best.pth.tar\"\n",
    "lr = 3e-3\n",
    "epochs = 100\n",
    "\n",
    "model_name = f\"__VGG16_{stype}_prune_{sparsity:.2f}_q\"\n",
    "fdir = 'result/' + model_name\n",
    "\n",
    "model = VGG16()\n",
    "attach_prune(model)\n",
    "checkpoint = torch.load(float_model_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_pruned(model)\n",
    "\n",
    "val_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, fdir, criterion, optimizer, epochs, stype=stype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16().cuda()\n",
    "attach_prune(model)\n",
    "quantize_pruned(model)\n",
    "\n",
    "checkpoint = torch.load(f'{fdir}/model_best.pth.tar', weights_only=False)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "l_to_save = 27\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "save_output = SaveOutput()\n",
    "model.features[l_to_save].register_forward_pre_hook(save_output)\n",
    "\n",
    "print(f'Acc: {val_model(model):.2%}')\n",
    "\n",
    "print_sparsity(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = model.features[l_to_save]\n",
    "nz_idx = (l.weight_q.sum(dim=-1).sum(dim=-1) != 0).nonzero()\n",
    "print(l.weight_q[nz_idx[:,0],nz_idx[:,1],:,:][-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_output.outputs[0][0][:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Weight int: \\n{(model.features[l_to_save].weight_q.data / (model.features[l_to_save].weight_quant.wgt_alpha.data.item()/(2**(4-1)-1)))[0,nz_idx[0]]}')\n",
    "x = save_output.outputs[0][0]\n",
    "x_alpha = model.features[l_to_save].act_alpha.data.item()\n",
    "x_delta = x_alpha / (2**(4)-1)\n",
    "act_q = act_quantization(4)\n",
    "x_q = act_q(x, x_alpha)\n",
    "print(f'Act int: \\n{(x_q/x_delta)[:2,:2]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
